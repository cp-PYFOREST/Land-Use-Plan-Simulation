---
editor: 
  markdown: 
    wrap: 72
---

```{r}
library(sf)
library(tidyverse)
library(here)
library(units)
library(knitr)
library(tictoc)
library(flextable)
library(parallel)
library(purrr)
library(foreach)
library(doParallel)
library(furrr)
library(beepr)
library(gt)
```

# LUP SCRIPT MUST BE ADJUSTED FOR 50% FOREST RESERVE

```{r}
#source(knitr::purl(here("src", "boundary_registry_data.qmd")))
source(knitr::purl(here('src', "lup_simulator.qmd")))

```

```{r}
limit_lu <- st_read('/Users/romero61/../../capstone/pyforest/data/mock_properties/mock_properties.shp')

#to read in rework if not loaded
# limit_lu <- st_read("/Users/romero61/../../capstone/pyforest/data/rework/rwk_over28.gpkg")

hydro <- st_read('/Users/romero61/../../capstone/pyforest/data/river_buffer/river_buffer.gpkg')

```

# Parallel Functions

```{r}
# create a vector of unique combinations of width_paddock # Function to create unique combinations of width_paddock and height_paddock
create_paddock_dims <- function() {
  expand_grid(width_paddock = 1:4, height_paddock = 1:4) %>%
    subset(width_paddock != height_paddock | width_paddock == 1)
}
```

```{r}
generate_statistics <-
  function(property_boundary,
           width_paddock,
           height_paddock,
           forest_reserve,
           paddocks,
           final_hedgerow,
           riparian_area,
           riparian_area_per) {
     # print("Inside generate_statistics")
    # 
    # print("Checking property_boundary")
    # print(property_boundary)
    # print("Checking forest_reserve")
    # print(forest_reserve)
    # print("Checking paddocks")
    # print(paddocks)
    # print("Checking final_hedgerow")
    # print(final_hedgerow)
    # print('Checking property')
    # print(property_boundary$cat)
    # print("Checking riparians")
    # print(riparian_area)
    # print(riparian_area_per)

    statistics <- tibble(
      cat = property_boundary$cat,
      ratio_xy = paste(width_paddock, "/", height_paddock),
      property_area = st_area(property_boundary) |> drop_units(),
      property_units = "m^2",
      
      fr_area = sum(st_area(forest_reserve)) |> drop_units(),
      fr_units = "m^2",
      fr_per = round((sum((st_area(forest_reserve)) / st_area(property_boundary))) * 100,2) |> drop_units(),
      
      paddocks_area = round(sum(st_area(paddocks)),2) |> drop_units(),
      paddocks_units = "m^2",
      paddocks_per = round(sum(st_area(paddocks)) / st_area(property_boundary)* 100 ,2) |>  drop_units(),
      
      hedgerow_area = ifelse(is.null(final_hedgerow), NA, st_area(final_hedgerow)),
      hedgerow_per =  round((sum(st_area(final_hedgerow)) / st_area(property_boundary)) * 100,2) |> drop_units(),
      
      riparian_area = riparian_area ,
      riparian_units = 'm^2',
      riparian_per = riparian_area_per
    )
  #   log_message <- paste("stats:", nrow(statistics), "\n")
  # cat(log_message, file = "log.txt", append = TRUE)
    return(statistics)
  }
```

```{r}
#| include: false

# Function to process a single property and paddock dimension
process_property <- function(property_id, width_paddock, height_paddock) {
   #print("Starting process_property function") # Add this line
  # Your code for processing a single property and paddock dimension
  # Here you should use the provided property_id, width_paddock, and height_paddock
  # instead of the values from the loops.
  # 
  # print(paste(
  #   'id',
  #   property_id,
  #   'width_paddock',
  #   width_paddock,
  #   "Height",
  #   height_paddock
  # ))
  
  results_df <- data.frame()
    tryCatch({
      #print("Inside tryCatch block")


  property_id <- as.integer(property_id)
  # Select Property
  #print("Selecting property")
  property_boundary <- select_property(property_id)
  
  # Riparian Corridor check
  #print("Checking riparian corridor")
  riparian_corridor <- riparian_buffer(boundary_property = property_boundary,
           hydrology = hydro)
  

  # Property dimensions
 #print("Calculating property dimensions")
  pad_hedg_dim <- property_dimensions(
    desired_area = 300000,
    hedgerow_width = 100,
    width_paddock = width_paddock,
    height_paddock = height_paddock)
  
  # Create Grid , Rotate, Cut With Property
 #print("Creating grid, rotating, and cutting with property")
  property_grid <- grid_rotate(property_boundary, pad_hedg_dim)
  
  # Cut Grid w/ River
  #print("Cutting grid with river")
  property_fragment <- riparian_cut(riparian_corridor, property_grid)

  # Create Forest Reserve â‰¥ 25% 
  #print("Calculating forest reserve")
  forest_reserve <- reserve(property_fragment,property_boundary)
  
  # Property w/o reserve area
  # 
  #print("Calculating remaining area without forest reserve")
  property_remaining <- no_reserve_area(grid_property = property_fragment,
                  fr_union = forest_reserve)

  # Hedgerows
  #print("Dividing area into paddocks and hedgerows")
  hedgerows <- make_hedges(property_remaining)
  
  hedge <- st_erase(hedgerows, property_boundary)
  hedges <- st_difference(hedgerows, hedge)
  cut_reserve <- st_intersection(forest_reserve, hedges)
  hedges <- st_difference(hedges, cut_reserve) |> st_simplify(dTolerance = 10)
    
  #print("After processing hedgerows")
  
  # Paddocks
  paddocks <- make_paddocks(property_remaining, hedgerows)
 
  #print("After processing paddocks")
  # If there is a corridor cut edges
  if(is.null(riparian_corridor) == FALSE) {
  riparian_area <- sum(round(st_area(riparian_corridor),2))
  riparian_area_per <-
    sum((st_area(riparian_corridor)) / st_area(property_boundary)) * 100
     final_hedgerow <- st_difference(hedges, riparian_corridor) |> st_sf() |>
   st_collection_extract(type = 'POLYGON')
    
  } else{
    riparian_area <- NA
    riparian_area_per <- NA
    final_hedgerow <- hedges
  }
  
  
  
# print("Calculating final statistics")
#    log_message <- paste("Processing property_id:", property_id, "width_paddock:", width_paddock, "height_paddock:", height_paddock, "\n")
# cat(log_message, file = "log.txt", append = TRUE)
# print(log_message)

  
  # Final Areas
   statistics <-
     generate_statistics(
       property_boundary,
       width_paddock,
       height_paddock,
       forest_reserve,
       paddocks,
       final_hedgerow,
       riparian_area,
       riparian_area_per
     )
   # print('Check return of statistics')
   # print(paste("Number of rows in statistics:", nrow(statistics)))

  results_df <- bind_rows(results_df,statistics)

  #print("Done with process_property function")
  },
  
   error = function(e) {
     error_tibble <- tibble(
       cat = paste(property_id,width_paddock, height_paddock),
       error = as.character(e)
     )
   results_df <- bind_rows(results_df, error_tibble)
   })
  #print("After tryCatch block")
  #print(paste("Returning result for property_id:", property_id, ", width_paddock:", width_paddock, ", height_paddock:", height_paddock))
  #print(paste("Number of rows in statistics:", nrow(results_df$statistics)))
  # print(paste("Number of rows in results_df:", nrow(results_df)))
  

  return(results_df)
  }
  

```

# Function for furrr

```{r}
process_property_nested <- function(property_id, width_paddock, height_paddock) {
  result <- process_property(property_id, width_paddock, height_paddock)
  return(result)
}



```

# furrr

```{r}
#| include: false
#| warning: false
tic()
# Make sure to register the number of cores you want to use for parallel processing
plan(multisession, workers = 19)

# Create a list of property ids
property_ids <- unique(limit_lu$cat)

# Create paddock dimensions
paddock_dims <- create_paddock_dims()

# Run the process_property function for each property id and paddock dimension
results <- future_map_dfr(property_ids, function(property_id) {
  future_pmap_dfr(list(
    width_paddock = paddock_dims$width_paddock,
    height_paddock = paddock_dims$height_paddock
  ), function(width_paddock, height_paddock) {
    process_property_nested(property_id, width_paddock, height_paddock)
  })
})

# Combine the results
results_df <- bind_rows(results)
toc()
```

19 properties 1778.145 sec elapsed purrr 19 properties 209.476 sec
elapsed furrr 5608properties 21535.431 sec elapsed furrr 5608 properties
22472.561 sec elapsed furrr 797 properies 3209.14 sec elapsed 1863
properies 6320.93 sec elapsed 1607 properties
4649 1411

# Saving results to data folder

```{r}
#
# results_df5608 25%
# result_df5608_increase 50%
#saveRDS(results, '~/../../capstone/pyforest/data/results_5608/results5608.rds')
#saveRDS(results, '~/../../capstone/pyforest/data/results_5608/results5608_increase.rds')

```

# Reload data

```{r}
# load in results as running script again will overwrite results variable

result5608_increase <- readRDS("/Users/romero61/../../capstone/pyforest/data/results_5608/results5608_50.rds")
```

# Optimal ratios and paddocks sizes

```{r}
# Arrange the data by property_id, highest paddocks_area, and fr_area, and separate ratio_xy into width_paddock and height_paddock.
# Resulting dataset is optimal ratios 
optimal <- result5608_increase %>%
  group_by(cat) %>%
  arrange(cat, desc(paddocks_area), desc(fr_area)) %>%
  slice(1) %>%
  ungroup() %>%
  separate(ratio_xy, into = c("width_paddock", "height_paddock"), sep = "/", convert = TRUE, remove = FALSE)


# Optimal needs to be reworked into smaller paddocks subset properties with greater than 28% forest reserve

optimal_53 <- optimal |> 
  filter(fr_per > 53) # on review this should have been just greater than but leaving for reproducibility # FOR 25%, NOW WE'LL USE JUST GREATER THAN for 50% use >

# subset limit_lu to properties that need to be reworked into smaller paddocks. First rework paddock area reduced to 990000 down from 999999
# 
#record of which properties to be reworked
rework_over53 <- limit_lu |> 
  filter(cat %in%  optimal_53$cat)

limit_lu <- rework_over53 #run 1863 properties  paddocks = 990000
```

# FOR CONSISTENCY FOLLOW THE SAME PATTERN AS 25% BUT WOULD PREFER TO TAKE BIGGER JUMPS

```{r}
# save new reworked dataset
# 
#optimalrwk_result <- results
#saveRDS(results, '~/../../capstone/pyforest/data/rework/results_rwk53_increase.rds')
optimalrwk_result <- readRDS('~/../../capstone/pyforest/data/rework/results_rwk53_increase.rds')
optimal_rwk <- optimalrwk_result %>% 
  group_by(cat) %>%
  arrange(cat, desc(paddocks_area), desc(fr_area)) %>%
  slice(1) %>%
  ungroup() %>%
  separate(ratio_xy, into = c("width_paddock", "height_paddock"), sep = "/", convert = TRUE, remove = FALSE) # 1863 properties





# Second Subset
optimal_53_2 <- optimal_rwk |> 
  filter(fr_per > 53)




#record of which properties to be reworked
rework_over53_2 <- limit_lu |> 
  filter(cat %in%  optimal_53_2$cat)

limit_lu <- rework_over53_2 #run 1607 properties  paddocks = 980000
```




```{r}
# save second new reworked dataset
# 
#optimalrwk_result2 <- results
#saveRDS(results, '~/../../capstone/pyforest/data/rework/results_rwk53_2_increase.rds')
optimalrwk_result2 <- readRDS( '~/../../capstone/pyforest/data/rework/results_rwk53_2_increase.rds')
optimal_rwk2 <- optimalrwk_result2 %>% 
  group_by(cat) %>%
  arrange(cat, desc(paddocks_area), desc(fr_area)) %>%
  slice(1) %>%
  ungroup() %>%
  separate(ratio_xy, into = c("width_paddock", "height_paddock"), sep = "/", convert = TRUE, remove = FALSE) # 1607 properties



# Third Subset 
optimal_53_3 <- optimal_rwk2 |> 
  filter(fr_per > 53) 


#record of which properties to be reworked
rework_over28_3 <- limit_lu |> 
  filter(cat %in%  optimal_53_3$cat)

limit_lu <- rework_over28_3 # run 1411 properties paddocks = 950000
```

```{r}
# save third new reworked dataset
# 
#optimalrwk_result3 <- results
#saveRDS(results, '~/../../capstone/pyforest/data/rework/results_rwk53_3increase.rds')
optimalrwk_result3 <- readRDS( '~/../../capstone/pyforest/data/rework/results_rwk53_3increase.rds')
optimal_rwk3 <- optimalrwk_result3 %>% 
  group_by(cat) %>%
  arrange(cat, desc(paddocks_area), desc(fr_area)) %>%
  slice(1) %>%
  ungroup() %>%
  separate(ratio_xy, into = c("width_paddock", "height_paddock"), sep = "/", convert = TRUE, remove = FALSE) # 1411 properties


# FOURTH Subset 
optimal_53_4 <- optimal_rwk3 |> 
  filter(fr_per > 53) 

#record of which properties to be reworked
rework_over53_4 <- limit_lu |> 
  filter(cat %in%  optimal_53_4$cat)

limit_lu <- rework_over53_4 # run 1001 properties Paddocks = 900000
```

```{r}
# save fourth new reworked dataset
# 
#optimalrwk_result4 <- results
#saveRDS(results, '~/../../capstone/pyforest/data/rework/results_rwk53_4_increase.rds')
optimalrwk_result4 <- readRDS( '~/../../capstone/pyforest/data/rework/results_rwk53_4_increase.rds')
optimal_rwk4 <- optimalrwk_result4 %>% 
  group_by(cat) %>%
  arrange(cat, desc(paddocks_area), desc(fr_area)) %>%
  slice(1) %>%
  ungroup() %>%
  separate(ratio_xy, into = c("width_paddock", "height_paddock"), sep = "/", convert = TRUE, remove = FALSE) # 1001 properties

# FIFTH Subset 
optimal_53_5 <- optimal_rwk4 |> 
  filter(fr_per > 53)

#record of which properties to be reworked
rework_over53_5 <- limit_lu |> 
  filter(cat %in%  optimal_53_5$cat)

limit_lu <- rework_over53_5 # run 553 properties Paddocks = 800000
```

```{r}
# save fifth new reworked dataset
# 
#optimalrwk_result5 <- results
#saveRDS(results, '~/../../capstone/pyforest/data/rework/results_rwk53_5_increase.rds')
optimalrwk_result5 <- readRDS( '~/../../capstone/pyforest/data/rework/results_rwk53_5_increase.rds')
optimal_rwk5 <- optimalrwk_result5 %>% 
  group_by(cat) %>%
  arrange(cat, desc(paddocks_area), desc(fr_area)) %>%
  slice(1) %>%
  ungroup() %>%
  separate(ratio_xy, into = c("width_paddock", "height_paddock"), sep = "/", convert = TRUE, remove = FALSE) # 533 properties


# Sixth Subset 
optimal_53_6 <- optimal_rwk5 |> 
  filter(fr_per > 53)

#record of which properties to be reworked
rework_over53_6 <- limit_lu |> 
  filter(cat %in%  optimal_53_6$cat)

limit_lu <- rework_over53_6 # run 325 properties Paddocks = 700000
```

```{r}
# save sixth new reworked dataset
# 
#optimalrwk_result6 <- results
#saveRDS(results, '~/../../capstone/pyforest/data/rework/results_rwk53_6_increase.rds')
optimalrwk_result6 <- readRDS( '~/../../capstone/pyforest/data/rework/results_rwk53_6_increase.rds')
optimal_rwk6 <- optimalrwk_result6 %>% 
  group_by(cat) %>%
  arrange(cat, desc(paddocks_area), desc(fr_area)) %>%
  slice(1) %>%
  ungroup() %>%
  separate(ratio_xy, into = c("width_paddock", "height_paddock"), sep = "/", convert = TRUE, remove = FALSE)# 325 properties



# Seventh Subset 
optimal_53_7 <- optimal_rwk6 |> 
  filter(fr_per > 53)

#record of which properties to be reworked
rework_over53_7 <- limit_lu |> 
  filter(cat %in%  optimal_53_7$cat)

limit_lu <- rework_over53_7 # run 174 properties Paddocks = 650000
```

```{r}
# save seventh new reworked dataset
# 
#optimalrwk_result7 <- results
#saveRDS(results, '~/../../capstone/pyforest/data/rework/results_rwk53_7_increase.rds')
optimalrwk_result7 <- readRDS( '~/../../capstone/pyforest/data/rework/results_rwk53_7_increase.rds')
optimal_rwk7 <- optimalrwk_result7 %>% 
  group_by(cat) %>%
  arrange(cat, desc(paddocks_area), desc(fr_area)) %>%
  slice(1) %>%
  ungroup() %>%
  separate(ratio_xy, into = c("width_paddock", "height_paddock"), sep = "/", convert = TRUE, remove = FALSE)# 174 properties

# Eighth Subset 
optimal_53_8 <- optimal_rwk7 |> 
  filter(fr_per > 53)
#record of which properties to be reworked
rework_over53_8 <- limit_lu |> 
  filter(cat %in%  optimal_53_8$cat)

limit_lu <- rework_over53_8 # run 106 properties Paddocks = 600000
```



```{r}
# save  new reworked dataset
# 
#optimalrwk_result8 <- results
#saveRDS(results, '~/../../capstone/pyforest/data/rework/results_rwk53_8_increase.rds')
optimalrwk_result8 <- readRDS( '~/../../capstone/pyforest/data/rework/results_rwk53_8_increase.rds')
optimal_rwk8 <- optimalrwk_result8 %>% 
  group_by(cat) %>%
  arrange(cat, desc(paddocks_area), desc(fr_area)) %>%
  slice(1) %>%
  ungroup() %>%
  separate(ratio_xy, into = c("width_paddock", "height_paddock"), sep = "/", convert = TRUE, remove = FALSE)# 106 properties


# Ninth Subset 
optimal_53_9 <- optimal_rwk8 |> 
  filter(fr_per > 53)
#record of which properties to be reworked
rework_over53_9 <- limit_lu |> 
  filter(cat %in%  optimal_53_9$cat)

limit_lu <- rework_over53_9 # run 64 properties Paddocks = 550000
```


```{r}
# save  new reworked dataset
# 
#optimalrwk_result9 <- results
#saveRDS(results, '~/../../capstone/pyforest/data/rework/results_rwk53_9_increase.rds')
optimalrwk_result9 <- readRDS( '~/../../capstone/pyforest/data/rework/results_rwk53_9_increase.rds')
optimal_rwk9 <- optimalrwk_result9 %>% 
  group_by(cat) %>%
  arrange(cat, desc(paddocks_area), desc(fr_area)) %>%
  slice(1) %>%
  ungroup() %>%
  separate(ratio_xy, into = c("width_paddock", "height_paddock"), sep = "/", convert = TRUE, remove = FALSE)# 64 properties


# Ninth Subset 
optimal_53_10 <- optimal_rwk9 |> 
  filter(fr_per > 53)
#record of which properties to be reworked
rework_over53_10 <- limit_lu |> 
  filter(cat %in%  optimal_53_10$cat)

limit_lu <- rework_over53_10 # run 28 properties Paddocks = 500000
```


```{r}
# save  new reworked dataset
# 
#optimalrwk_result10 <- results
#saveRDS(results, '~/../../capstone/pyforest/data/rework/results_rwk53_10_increase.rds')
optimalrwk_result10 <- readRDS( '~/../../capstone/pyforest/data/rework/results_rwk53_10_increase.rds')
optimal_rwk10 <- optimalrwk_result10 %>% 
  group_by(cat) %>%
  arrange(cat, desc(paddocks_area), desc(fr_area)) %>%
  slice(1) %>%
  ungroup() %>%
  separate(ratio_xy, into = c("width_paddock", "height_paddock"), sep = "/", convert = TRUE, remove = FALSE) # 28 properties


# Tenth Subset 
optimal_53_11 <- optimal_rwk10 |> 
  filter(fr_per > 53)
#record of which properties to be reworked
rework_over53_11 <- limit_lu |> 
  filter(cat %in%  optimal_53_11$cat)

limit_lu <- rework_over53_11 # run 11 properties Paddocks = 450000
```

```{r}
# save  new reworked dataset
# 
#optimalrwk_result11 <- results
#saveRDS(results, '~/../../capstone/pyforest/data/rework/results_rwk53_11_increase.rds')
optimalrwk_result11 <- readRDS( '~/../../capstone/pyforest/data/rework/results_rwk53_11_increase.rds')
optimal_rwk11 <- optimalrwk_result11 %>% 
  group_by(cat) %>%
  arrange(cat, desc(paddocks_area), desc(fr_area)) %>%
  slice(1) %>%
  ungroup() %>%
  separate(ratio_xy, into = c("width_paddock", "height_paddock"), sep = "/", convert = TRUE, remove = FALSE)# 11 properties


# Eleventh Subset 
optimal_53_12 <- optimal_rwk11 |> 
  filter(fr_per > 53)
#record of which properties to be reworked
rework_over53_12 <- limit_lu |> 
  filter(cat %in%  optimal_53_12$cat)

limit_lu <- rework_over53_12 # run 8 properties Paddocks = 400000
```


```{r}
# save  new reworked dataset
# 
#optimalrwk_result12 <- results
#saveRDS(results, '~/../../capstone/pyforest/data/rework/results_rwk53_12_increase.rds')
optimalrwk_result12 <- readRDS( '~/../../capstone/pyforest/data/rework/results_rwk53_12_increase.rds')
optimal_rwk12<- optimalrwk_result12 %>% 
  group_by(cat) %>%
  arrange(cat, desc(paddocks_area), desc(fr_area)) %>%
  slice(1) %>%
  ungroup() %>%
  separate(ratio_xy, into = c("width_paddock", "height_paddock"), sep = "/", convert = TRUE, remove = FALSE) # 8 properties


# Twelfth Subset 
optimal_53_13 <- optimal_rwk12 |> 
  filter(fr_per > 53)
#record of which properties to be reworked
rework_over53_13 <- limit_lu |> 
  filter(cat %in%  optimal_53_13$cat)

limit_lu <- rework_over53_13 # run 2 properties Paddocks = 350000
```

```{r}
# save  new reworked dataset
# 
#optimalrwk_result13 <- results
#saveRDS(results, '~/../../capstone/pyforest/data/rework/results_rwk53_13_increase.rds')
optimalrwk_result13 <- readRDS( '~/../../capstone/pyforest/data/rework/results_rwk53_13_increase.rds')
optimal_rwk13 <- optimalrwk_result13 %>% 
  group_by(cat) %>%
  arrange(cat, desc(paddocks_area), desc(fr_area)) %>%
  slice(1) %>%
  ungroup() %>%
  separate(ratio_xy, into = c("width_paddock", "height_paddock"), sep = "/", convert = TRUE, remove = FALSE)# 2 properties



# Thirteenth Subset 
optimal_53_14 <- optimal_rwk13 |> 
  filter(fr_per > 53)
#record of which properties to be reworked
rework_over53_14 <- limit_lu |> 
  filter(cat %in%  optimal_53_14$cat)

limit_lu <- rework_over53_14 # run 1 properties Paddocks = 300000
```

```{r}
# save  new reworked dataset
# 
#optimalrwk_result14 <- results
#saveRDS(results, '~/../../capstone/pyforest/data/rework/results_rwk53_14_increase.rds')
optimalrwk_result14 <- readRDS( '~/../../capstone/pyforest/data/rework/results_rwk53_14_increase.rds')
optimal_rwk14 <- optimalrwk_result14 %>% 
  group_by(cat) %>%
  arrange(cat, desc(paddocks_area), desc(fr_area)) %>%
  slice(1) %>%
  ungroup() %>%
  separate(ratio_xy, into = c("width_paddock", "height_paddock"), sep = "/", convert = TRUE, remove = FALSE) # 1 properties
```


```{r}

# find reverse to gather less than 53 properties
optimal_53_r <- optimal |> 
  filter(fr_per <= 53)  #important to use less than to not introduce duplicates from first initial error of using >= instead of just >.

optimal_53_2_r <- optimal_rwk |> 
  filter(fr_per <= 53)

optimal_53_3_r <- optimal_rwk2 |> 
  filter(fr_per <= 53) 

optimal_53_4_r <- optimal_rwk3 |> 
  filter(fr_per <= 53) 

optimal_53_5_r <- optimal_rwk4 |> 
  filter(fr_per <= 53)

# Sixth Subset 
optimal_53_6_r <- optimal_rwk5 |> 
  filter(fr_per <= 53)

optimal_53_7_r <- optimal_rwk6 |> 
  filter(fr_per <= 53)

optimal_53_8_r <- optimal_rwk7 |> 
  filter(fr_per <= 53)

optimal_53_9_r <- optimal_rwk8 |> 
  filter(fr_per <= 53)

optimal_53_10_r <- optimal_rwk9 |> 
  filter(fr_per <= 53)

optimal_53_11_r <- optimal_rwk10 |> 
  filter(fr_per <= 53)

optimal_53_12_r <- optimal_rwk11 |> 
  filter(fr_per <= 53)

optimal_53_13_r <- optimal_rwk12 |> 
  filter(fr_per <= 53)

optimal_53_14_r <- optimal_rwk13 |> 
  filter(fr_per <= 53)

optimal_rwk14

# add in paddock size for those properties
optimal_53_r <- optimal_53_r %>% mutate(paddock_size = 999999)
optimal_53_2_r <- optimal_53_2_r %>% mutate(paddock_size = 990000)
optimal_53_3_r <- optimal_53_3_r %>% mutate(paddock_size = 980000)
optimal_53_4_r <- optimal_53_4_r %>% mutate(paddock_size = 950000)
optimal_53_5_r <- optimal_53_5_r %>% mutate(paddock_size = 900000)
optimal_53_6_r <- optimal_53_6_r %>% mutate(paddock_size = 800000)
optimal_53_7_r <- optimal_53_7_r %>% mutate(paddock_size = 700000)
optimal_53_8_r <- optimal_53_8_r %>% mutate(paddock_size = 650000)
optimal_53_9_r <- optimal_53_9_r %>% mutate(paddock_size = 600000)
optimal_53_10_r <- optimal_53_10_r %>% mutate(paddock_size = 550000)
optimal_53_11_r <- optimal_53_11_r %>% mutate(paddock_size = 500000)
optimal_53_12_r <- optimal_53_12_r %>% mutate(paddock_size = 450000)
optimal_53_13_r <- optimal_53_13_r %>% mutate(paddock_size = 400000) 
optimal_53_14_r <-  optimal_53_14_r |>  mutate(paddock_size = 350000)
optimal_rwk14 <- optimal_rwk14 %>% mutate(paddock_size = 300000)


optimal_xy <- bind_rows(optimal_53_r, optimal_53_2_r, optimal_53_3_r, optimal_53_4_r, optimal_53_5_r, optimal_53_6_r, optimal_53_7_r, optimal_53_8_r, optimal_53_9_r, optimal_53_10_r, optimal_53_11_r, optimal_53_12_r, optimal_53_13_r, optimal_53_14_r, optimal_rwk14) |> 
  separate(ratio_xy, into = c("width_paddock", "height_paddock"), sep = "/", convert = TRUE, remove = FALSE)






# Finally, save the optimal xy for each property to create a lup with 50% forest reserve
# 
saveRDS(optimal_xy, '/Users/romero61/../../capstone/pyforest/data/results_5608/optimal_xy_50.rds')
```





```{r}
# dataset to create map
# 
#reread mock properties
limit_lu <- st_read('/Users/romero61/../../capstone/pyforest/data/mock_properties/mock_properties.shp')

optimal_mock_properties <- limit_lu |> 
  left_join(optimal_xy %>%
              select(cat, width_paddock, height_paddock, paddock_size),
            by = "cat")
#save 
#st_write(optimal_mock_properties, '/Users/romero61/../../capstone/pyforest/data/optimal_mock_properties/optimal_mock_properties_50.gpkg')
```
# Code for dealing with missing rows or duplicates

```{r}
# 
# # Find the difference between the unique key columns
# missing_id <- setdiff(optimal$cat, optimal_xy$cat)
# 
# # Get the missing row in the 'optimal' dataset
# missing_row <- optimal[optimal$cat %in% missing_id,]
# 
# # Print the missing row
# print(missing_row)

```


```{r}
# #Afte process lost a row so trying to find where
# print("Before first filter:")
# print(filter(optimal_rwk, cat == 5193))
# 
# #Afte process lost a row so trying to find where
# print("After filter <number>:")
# print(filter(optimal_53_2, cat == 5193))
# 
# 
# #Afte process lost a row so trying to find where
# print("Before first filter:")
# print(filter(optimal_rwk2, cat == 5193))
# 
# #Afte process lost a row so trying to find where
# print("After filter <number>:")
# print(filter(optimal_53_3, cat == 5193))
# 
# 
# #Afte process lost a row so trying to find where
# print("Before first filter:")
# print(filter(optimal_rwk3, cat == 5193))
# 
# #Afte process lost a row so trying to find where
# print("After filter <number>:")
# print(filter(optimal_53_4, cat == 5193))
# 
# 
# #Afte process lost a row so trying to find where
# print("Before first filter:")
# print(filter(optimal_rwk4, cat == 5193))
# 
# #Afte process lost a row so trying to find where
# print("After filter <number>:")
# print(filter(optimal_53_5, cat == 5193))
# 
# 
# #Afte process lost a row so trying to find where
# print("Before first filter:")
# print(filter(optimal_rwk5, cat == 5193))
# 
# #Afte process lost a row so trying to find where
# print("After filter <number>:")
# print(filter(optimal_53_6, cat == 5193))
# 
# #Afte process lost a row so trying to find where
# print("Before first filter:")
# print(filter(optimal_rwk6, cat == 5193))
# 
# #Afte process lost a row so trying to find where
# print("After filter <number>:")
# print(filter(optimal_53_7, cat == 5193))
# 
# #Afte process lost a row so trying to find where
# print("Before first filter:")
# print(filter(optimal_rwk7, cat == 5193))
# 
# #Afte process lost a row so trying to find where
# print("After filter <number>:")
# print(filter(optimal_53_8, cat == 5193))
# 
# #Afte process lost a row so trying to find where
# print("Before first filter:")
# print(filter(optimal_rwk8, cat == 5193))
# 
# #Afte process lost a row so trying to find where
# print("After filter <number>:")
# print(filter(optimal_53_9, cat == 5193))
# 
# #Afte process lost a row so trying to find where
# print("Before first filter:")
# print(filter(optimal_rwk9, cat == 5193))
# 
# #Afte process lost a row so trying to find where
# print("After filter <number>:")
# print(filter(optimal_53_10, cat == 5193))
# 
# #Afte process lost a row so trying to find where
# print("Before first filter:")
# print(filter(optimal_rwk4, cat == 5193))
# 
# #Afte process lost a row so trying to find where
# print("After filter <number>:")
# print(filter(optimal_53_5, cat == 5193))
# 
# #Afte process lost a row so trying to find where
# print("Before first filter:")
# print(filter(optimal_rwk4, cat == 5193))
# 
# #Afte process lost a row so trying to find where
# print("After filter <number>:")
# print(filter(optimal_53_5, cat == 5193))
# 
# #Afte process lost a row so trying to find where
# print("Before first filter:")
# print(filter(optimal_rwk4, cat == 5193))
# 
# #Afte process lost a row so trying to find where
# print("After filter <number>:")
# print(filter(optimal_53_5, cat == 5193))
# #Afte process lost a row so trying to find where
# print("Before first filter:")
# print(filter(optimal_rwk4, cat == 5193))
# 
# #Afte process lost a row so trying to find where
# print("After filter <number>:")
# print(filter(optimal_53_5, cat == 5193))
# #Afte process lost a row so trying to find where
# print("Before first filter:")
# print(filter(optimal_rwk4, cat == 5193))
# 
# #Afte process lost a row so trying to find where
# print("After filter <number>:")
# print(filter(optimal_53_5, cat == 5193))
# #Afte process lost a row so trying to find where
# print("Before first filter:")
# print(filter(optimal_rwk4, cat == 5193))
# 
# #Afte process lost a row so trying to find where
# print("After filter <number>:")
# print(filter(optimal_53_5, cat == 5193))
```

```{r}
# Code if you find final optimal_xy has more rows than initial limit_lu


# # Create the optimal_xy dataframe with potential duplicates
# optimal_xy_with_duplicates <-  bind_rows(optimal_53_r, optimal_53_2_r, optimal_53_3_r, optimal_53_4_r, optimal_53_5_r, optimal_53_6_r, optimal_53_7_r, optimal_53_8_r, optimal_53_9_r, optimal_53_10_r, optimal_53_11_r, optimal_53_12_r, optimal_53_13_r, optimal_rwk14) 
# cat_counts <- optimal_xy_with_duplicates %>%
#   count(cat) %>%
#   filter(n > 1)
#
# cat_counts
#
# duplicated_cat_rows <- optimal_xy_with_duplicates %>%
#   filter(cat %in% cat_counts$cat)
#
# duplicated_cat_rows

# Remove duplicates by selecting the first row of each group based on 'cat'
# optimal_xy <- optimal_xy_with_duplicates %>%
#   group_by(cat) %>%
#   slice(1) %>%
#   ungroup()
#
# optimal_xy
```


# Examine percentages
```{r}
percentages <- optimal_xy |>
  select(-riparian_area, -property_area, -property_units, -fr_area, -paddocks_area, -paddocks_units, - hedgerow_area, -fr_units) |>
  drop_units() |> 
  replace_na(replace = list(riparian_per = 0)) |> mutate(sum_percentage = fr_per + paddocks_per + hedgerow_per + riparian_per)
#saveRDS(statistics, "/Users/romero61/../../capstone/pyforest/data/results_df/statistics.rds")
theme_apa(flextable(percentages))
```
